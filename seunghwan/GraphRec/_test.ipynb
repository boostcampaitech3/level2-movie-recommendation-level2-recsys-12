{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3adc90fe-3b84-4efb-9cba-0609e8ba8e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections import deque\n",
    "from six import next\n",
    "from box import Box\n",
    "\n",
    "import torch\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "from dataset import GraphRecDataset\n",
    "from model import GraphRecModel\n",
    "from trainer import GraphRecTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf52fcc-965a-49d0-b1a6-cc8b49174ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    ##############datasets###############\n",
    "    'data_path' : '/opt/ml/input/data/train/',\n",
    "    'test_ratio' : 0.2,\n",
    "    'use_exist' : True, # test_ratio 바꾸면 한번 False 처리해서 다시 불러와야함!\n",
    "    'is_graph' : True,\n",
    "\n",
    "    'use_side_information' : True,\n",
    "    'side_titles' : False, # Not implement yet\n",
    "    'side_genres' : True,\n",
    "    'side_directors' : False, # Not implement yet\n",
    "    'side_writers' : False, # Not implement yet\n",
    "    'side_years' : True,\n",
    "    \n",
    "    #############optimizer###############\n",
    "    'lr' : 2e-4,\n",
    "    'wd' : 0.00,\n",
    "    \n",
    "    ##############model##################\n",
    "    'user_weight' : 0.008,\n",
    "    'movie_weight' : 0.006,\n",
    "    'mf_size' : 50,\n",
    "    \n",
    "    ##############trainer#################\n",
    "    'batch_size' : 256,\n",
    "    'epochs' : 5,\n",
    "    'num_negative' : 5,\n",
    "    \n",
    "    #################etc##################\n",
    "    'device' : 'cuda'\n",
    "    \n",
    "}\n",
    "args = Box(args)\n",
    "\n",
    "dirs = {\n",
    "    'ratings' : os.path.join(args.data_path, 'train_ratings.csv'),\n",
    "    'titles' : os.path.join(args.data_path, 'titles.tsv'),\n",
    "    'genres' : os.path.join(args.data_path, 'genres.tsv'),\n",
    "    'directors' : os.path.join(args.data_path, 'directors.tsv'),\n",
    "    'years' : os.path.join(args.data_path, 'years_new.tsv'),\n",
    "    'writers' : os.path.join(args.data_path, 'writers.tsv'),\n",
    "    'output' : './output/',\n",
    "    'model_output' : './model'\n",
    "}\n",
    "dirs = Box(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba60cbd-bfd5-4dd5-a4fb-2ea4ffd4a45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load existing train graphs!\n",
      "load train side information...\n",
      "load existing inference graphs!\n",
      "load inference side information...\n"
     ]
    }
   ],
   "source": [
    "dataset = GraphRecDataset(args, dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6a2ca0-e183-4783-9a71-bd2cb73fbd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8e289d-0ffa-4cc2-93af-ec11a35c9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af51760-d604-4563-b22f-64c7bbae2c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228dc7f5-9587-44eb-8d9f-8ee9241194a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a796819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphRecModel(args, dataset).to(args.device)\n",
    "model_best = GraphRecModel(args, dataset).to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1219144f-1a86-463e-a581-b765d157743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GraphRecTrainer(args, dirs, dataset,\n",
    "                         model, model_best, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "579d4423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 59/16108 [00:05<23:54, 11.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/input/code/_main/seunghwan/GraphRec/trainer.py:48\u001b[0m, in \u001b[0;36mGraphRecTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m) :\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs) :\n\u001b[0;32m---> 48\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_user_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_movie_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/input/code/_main/seunghwan/GraphRec/trainer.py:85\u001b[0m, in \u001b[0;36mGraphRecTrainer.__train\u001b[0;34m(self, data, user_graph, movie_graph)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# user_neg, movie_neg, label_neg = self.__negative_sampling(self.train_user_negative, \u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#                                                           self.train_movie_negative,\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#                                                           user_pos, movie_pos)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# movie_idx = np.concatenate((movie_pos, movie_neg))\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# target = np.concatenate((label_pos, label_neg))\u001b[39;00m\n\u001b[1;32m     84\u001b[0m user_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(user_graph[user_idx])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 85\u001b[0m movie_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[43mmovie_graph\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovie_idx\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     86\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(target)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#############################TRAIN############################\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "433922e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6375c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = data.sample(frac=1, random_state=42).reset_index(drop=True) \n",
    "total_length = len(shuffled_data)\n",
    "n_batches = np.ceil(total_length / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5fac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_graph = dataset.train_user_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ecc2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_graph = dataset.train_movie_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51d6a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b78c04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "user_data = np.array(shuffled_data['user'])\n",
    "movie_data = np.array(shuffled_data['item'])\n",
    "rating_data = np.array(shuffled_data['rating'])\n",
    "\n",
    "total_length = len(shuffled_data)\n",
    "n_batches = np.ceil(total_length / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a36b2979-7af3-465f-b029-0082797ed556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41dcf7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16108/16108 [23:14<00:00, 11.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.7058, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16108/16108 [13:29<00:00, 19.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(56.4256, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16108/16108 [21:26<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(60.5044, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2952/16108 [03:52<17:16, 12.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m movie_idx \u001b[38;5;241m=\u001b[39m movie_data[start_index:end_index]\n\u001b[1;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m rating_data[start_index:end_index]\n\u001b[0;32m---> 17\u001b[0m user_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[43muser_graph\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m movie_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(movie_graph[movie_idx])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(target)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(5):\n",
    "    shuffled_data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    user_data = np.array(shuffled_data['user'])\n",
    "    movie_data = np.array(shuffled_data['item'])\n",
    "    rating_data = np.array(shuffled_data['rating'])\n",
    "\n",
    "    total_length = len(shuffled_data)\n",
    "    n_batches = np.ceil(total_length / 256)\n",
    "    e_loss = 0.0\n",
    "    for start_index in tqdm(range(0, total_length, 256)) :\n",
    "        end_index = min(start_index + 256, total_length)\n",
    "\n",
    "        user_idx = user_data[start_index:end_index]\n",
    "        movie_idx = movie_data[start_index:end_index]\n",
    "        target = rating_data[start_index:end_index]\n",
    "\n",
    "        user_input = torch.FloatTensor(user_graph[user_idx]).to('cuda')\n",
    "        movie_input = torch.FloatTensor(movie_graph[movie_idx]).to('cuda')\n",
    "        target = torch.FloatTensor(target).to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred, regularizer = model(user_input, movie_input)\n",
    "        cost_l2 = torch.sum((target-pred)**2) / 2\n",
    "        loss = torch.add(cost_l2, regularizer)    \n",
    "        e_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(e_loss / n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa201645-a53e-4e62-93ba-301cc3e4203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b812d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.07567336],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.05002138],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.13381787],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.21205643],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.56263363],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.02821719]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a5e1c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6807, 38187)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_graph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa61c2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 38187)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6c6288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    23612\n",
       "3    16172\n",
       "4    30836\n",
       "Name: user, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adataset.train_data.iloc[[2,3,4]]['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbe85369",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = dataset.train_user_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0cf1412c-3842-4b7f-8288-ca309f2fa51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0, ..., 31359, 31359, 31359]),\n",
       " array([    0, 31360, 31378, ..., 37167, 37190, 38167]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3548033-32cc-4c54-8c10-39249a6a8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae6265e3-0108-4352-ac21-80f68078d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb0ab29e-8562-472b-bab8-175a7367fdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24188904-6182-440a-9e6f-1446be76445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4321809-bfc2-4d72-a2fa-f250483f6e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31360it [00:07, 4015.60it/s]\n"
     ]
    }
   ],
   "source": [
    "neg_dct = {}\n",
    "for ind, samples in tqdm(enumerate(dataset.train_user_graph)):\n",
    "    neg_dct[ind] = np.where(samples == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a54a08af-1761-40cc-a685-83dddb358b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    1,     2,     3, ..., 38164, 38165, 38166]),)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dataset.train_user_graph[0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa1f71-696d-4c45-b878-b8e201da3fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013e126-387a-4fb1-85ad-f31eed9edcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(pred,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "453cffd5-bcf3-4fca-87ea-462e07d73487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.loss.BCELoss"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45e3acb8-bb1b-480f-84cf-16e919dd063a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:3055\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3053\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3054\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m-> 3055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m   3056\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3057\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3059\u001b[0m     )\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "criterion(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf3c20-4cef-48a7-8057-e14a542bef6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
