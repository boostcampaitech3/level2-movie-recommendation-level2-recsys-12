{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "from utils import set_seed, check_path, EarlyStopping\n",
    "from data_preprocessing import *\n",
    "from dataset import get_dataloader\n",
    "from caser import Caser\n",
    "from metric import get_Recall, get_NDCG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from box import Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        train_dataloader,\n",
    "        valid_dataloader,\n",
    "        epochs,\n",
    "        dict_negative_samples,\n",
    "        num_neg_samples,\n",
    "        save_metric,\n",
    "        topK,\n",
    "        device,\n",
    "        output,\n",
    "        save_file_name,\n",
    "        patience,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_dataloader\n",
    "        self.valid_loader = valid_dataloader\n",
    "        self.neg_samples = dict_negative_samples\n",
    "        self.num_neg_samples = num_neg_samples\n",
    "        self.device = device\n",
    "        \n",
    "        self.early_stopping = EarlyStopping(\n",
    "            checkpoint_path=os.path.join(output, save_file_name), \n",
    "            patience=patience,\n",
    "            save_metric=save_metric\n",
    "            )\n",
    "        self.save_metric = save_metric\n",
    "        self.loss_list = list()\n",
    "        self.recall_list = list()\n",
    "        self.ndcg_list = list()\n",
    "\n",
    "        self.topK = topK\n",
    "    \n",
    "    def fit(self):\n",
    "        epoch_start = torch.cuda.Event(enable_timing=True)\n",
    "        epoch_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        self.model.to(device)\n",
    "        print('start training...')\n",
    "        for epoch in range(self.epochs):\n",
    "            # 시작 시간 기록\n",
    "            epoch_start.record()\n",
    "\n",
    "            avg_loss = self._train()\n",
    "            avg_recall, avg_ndcg = self._metric()\n",
    "        \n",
    "            epoch_end.record()\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            self.loss_list.append(avg_loss)\n",
    "            self.recall_list.append(avg_recall)\n",
    "            self.ndcg_list.append(avg_ndcg)\n",
    "\n",
    "\n",
    "            print(\n",
    "                f'Epoch[{epoch+1}/{self.epochs}]\\ttrain_loss: {avg_loss:.4f}' +\n",
    "                f'\\trecall: {avg_recall:.4f}\\tNDCG: {avg_ndcg:.4f} '+\n",
    "                f'\\t훈련시간: {epoch_start.elapsed_time(epoch_end)/1000:.2f} sec'\n",
    "            )\n",
    "\n",
    "            if self.save_metric == 'loss': score = avg_loss\n",
    "            elif self.save_metric == 'ndcg': score = avg_ndcg\n",
    "            else: score = avg_recall\n",
    "\n",
    "            self.early_stopping(score, self.model)\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "        \n",
    "        print('finish training!')\n",
    "\n",
    "\n",
    "    def _train(self):\n",
    "        self.model.train()\n",
    "        size = len(self.train_loader)\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for users, sequence, sequence_target in self.train_loader:\n",
    "            users = users.to(self.device)\n",
    "            sequence = sequence.to(self.device)\n",
    "            target_pos = sequence_target.to(self.device)\n",
    "            target_neg = self._get_neg_smaples(users, self.num_neg_samples).to(self.device)\n",
    "\n",
    "            input_targets = torch.cat((target_pos, target_neg), dim=-1)\n",
    "            ground_truth = self._get_GT(target_pos.shape[0], target_pos.shape[1]).to(self.device)\n",
    "\n",
    "            predict = self.model(users, sequence, input_targets)\n",
    "\n",
    "            print(input_targets.shape)\n",
    "            print(ground_truth.shape)\n",
    "            print(predict.shape)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.criterion(predict, ground_truth)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / size\n",
    "\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "    def _metric(self):\n",
    "        self.model.eval()\n",
    "        size = len(self.valid_loader)\n",
    "\n",
    "        epoch_recall, epoch_ndcg = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for users, sequence, sequence_target in self.valid_loader:\n",
    "                users = users.to(self.device)\n",
    "                sequence = sequence.to(self.device)\n",
    "                target_pos = sequence_target.to(self.device)\n",
    "                all_neg_targets = self._get_neg_smaples(users).to(self.device)\n",
    "\n",
    "                input_targets = torch.cat((target_pos, all_neg_targets), dim=-1)\n",
    "                predict = self.model(users, sequence, input_targets, for_pred=True)\n",
    "                _, indices = torch.topk(predict, dim=0, k=self.topK)\n",
    "                rank_list = torch.take(input_targets, indices).cpu().numpy()\n",
    "                target_list = target_pos.squeeze().cpu().numpy()\n",
    "\n",
    "                epoch_recall += get_Recall(rank_list, target_list)\n",
    "                epoch_ndcg += get_NDCG(rank_list, target_list)\n",
    "\n",
    "        avg_hr = epoch_recall / size\n",
    "        avg_ndcg = epoch_ndcg / size\n",
    "\n",
    "        return avg_hr, avg_ndcg\n",
    "\n",
    "    \n",
    "    def _get_neg_smaples(self, users, num_neg=1e9):\n",
    "        neg_items = list()\n",
    "        users = users.detach().cpu().numpy()\n",
    "        for user in users:\n",
    "            items = np.random.choice(self.neg_samples[user], min(len(self.neg_samples[user]), num_neg), replace=False)\n",
    "            neg_items.append(items)\n",
    "        \n",
    "        return torch.from_numpy(np.array(neg_items)).long()\n",
    "\n",
    "    \n",
    "    def _get_GT(self, batch_size, num_pos):\n",
    "        np_pos = np.ones(shape=(batch_size, num_pos), dtype=np.int64)\n",
    "        np_neg = np.zeros(shape=(batch_size, self.num_neg_samples), dtype=np.int64)\n",
    "\n",
    "        np_gt = np.concatenate((np_pos, np_neg), axis=-1)\n",
    "\n",
    "        return torch.from_numpy(np_gt).float()\n",
    "\n",
    "def plot_loss(epochs, all_loss, model_name, dir_output, loss_name=['Loss', 'Recall', 'NDCG']):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(30, 7))\n",
    "    fig.suptitle(model_name, fontsize=30)\n",
    "    x_list = [i for i in range(1, epochs+1)]\n",
    "    \n",
    "    for i in range(3):\n",
    "        sns.lineplot(\n",
    "            x=x_list, y=all_loss[i],\n",
    "            ax = axes[i]\n",
    "        )\n",
    "\n",
    "        axes[i].set_ylabel(loss_name[i])\n",
    "        axes[i].set_xlabel('Epochs')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(dir_output, f'{model_name}.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    # config args\n",
    "    \"data_dir\": \"/opt/ml/input/data/train\",\n",
    "    \"output_dir\": \"output\",\n",
    "    \"data_file\": \"train_ratings.csv\",\n",
    "    \"seed\": 42,\n",
    "    \"num_valid_item\": 3,\n",
    "    \"topK\": 10,\n",
    "\n",
    "    # model args\n",
    "    'd': 100,\n",
    "    'nv': 4,\n",
    "    'nh': 16,\n",
    "    'drop': 0.5,\n",
    "    'ac_conv': 'relu',\n",
    "    'ac_fc': \"relu\",\n",
    "    \"L\": 5,\n",
    "    \"T\": 3,\n",
    "\n",
    "    # hyper args\n",
    "    \"batch_size\": 256,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_neg_samples\": 3,\n",
    "    \"epochs\": 50,\n",
    "    'l2': 1e-5,\n",
    "    'patience': 8,\n",
    "    'save_metric': 'ndcg',\n",
    "}\n",
    "\n",
    "\n",
    "config = Box(config)\n",
    "\n",
    "config.save_metric = config.save_metric.lower()\n",
    "assert config.save_metric in ['ndcg', 'recall', 'loss'], \"chooes metric among ndcg, recall and loss\"\n",
    "config.save_file_name = f\"best_{config.save_metric}_Caser.pt\"\n",
    "\n",
    "set_seed(config.seed)\n",
    "check_path(config.output_dir)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Use {device}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file and encode both user_id and item_id #\n",
    "config.data_file_path = os.path.join(config.data_dir, config.data_file)\n",
    "df_all = pd.read_csv(config.data_file_path)\n",
    "if 'rating' in df_all.columns.values: df_all = df_all.drop('rating', axis=1)\n",
    "column_list = df_all.columns.values\n",
    "df_all.rename(columns={column_list[0]: 'user_id', column_list[1]: 'item_id', column_list[2]: 'timestamp'}, inplace=True)\n",
    "encode_user_item_ids(df_all, inference=False)\n",
    "#################################################\n",
    "\n",
    "# get positive items sorted by timestamp and negavite items per user #\n",
    "unique_users, unique_items = df_all['user_id'].unique(), df_all['item_id'].unique()\n",
    "dict_user_item, dict_negative_samples = get_sequence_and_negative(df_all, unique_users, unique_items)\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data to train and test...\n",
      "done!\n",
      "make sequences...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# get train valid dataloader #\n",
    "dict_train, dict_valid = trian_test_split(dict_user_item, config.num_valid_item, unique_users)\n",
    "train_meta, valid_meta = to_sequence(dict_train, dict_valid, config.L, config.T)\n",
    "train_dataloader = get_dataloader(train_meta, config.batch_size)\n",
    "valid_dataloader = get_dataloader(valid_meta, 1)\n",
    "##############################\n",
    "\n",
    "# trainer args init #\n",
    "model = Caser(len(unique_users), len(unique_items), config)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.l2)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() # if necessary\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    epochs=config.epochs,\n",
    "    dict_negative_samples=dict_negative_samples,\n",
    "    num_neg_samples=config.num_neg_samples,\n",
    "    save_metric=config.save_metric,\n",
    "    topK=config.topK,\n",
    "    device=device,\n",
    "    output=config.output_dir,\n",
    "    save_file_name=config.save_file_name,\n",
    "    patience=config.patience\n",
    "    )\n",
    "\n",
    "trainer.fit()\n",
    "all_loss = [trainer.loss_list, trainer.recall_list, trainer.ndcg_list]\n",
    "plot_loss(config.epochs, all_loss, 'Caser', config.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
